

fn main() -> i32 {
	let group_size = 256;
	let num_groups = 42;

	let test = createBaseTest(0u32);

	// verify that only all lanes trigger wave barrier_all
	with device, device_memory, device_failed_flag in test.run_test() {
		with grid, intrinsics in device.launch_1d(num_groups, group_size) {
			with wave in grid.waves() {
				with thread in wave.threads() {
					for i in range(0, wave.num_threads() as i32) {

						let iami = if thread.idx(0) == i as u32 {1} else {0};
						let x = wave.barrier_all(iami);
						let passed = (x == 0);

						if !passed {
							thread.atomic_exch_global_u32(device_failed_flag, 1u32);
						}
					}

					if wave.barrier_all(1) != 1 {
						thread.atomic_exch_global_u32(device_failed_flag, 2u32);
					}
				}
			}
		}

		true
	}

	// verify that any lane can trigger wave barrier_any
	with device, device_memory, device_failed_flag in test.run_test() {
		with grid, intrinsics in device.launch_1d(num_groups, group_size) {
			with wave in grid.waves() {
				with thread in wave.threads() {
					for i in range(0, wave.num_threads() as i32) {

						let iami = if thread.idx(0) == i as u32 {1} else {0};
						let x = wave.barrier_any(iami);
						let passed = (x == 1);

						if !passed {
							thread.atomic_exch_global_u32(device_failed_flag, 3u32);
						}
					}

					if wave.barrier_any(0) != 0 {
						thread.atomic_exch_global_u32(device_failed_flag, 4u32);
					}
				}
			}
		}

		true
	}

	// verify that every vote counts in wave barrier_vote
	with device, device_memory, device_failed_flag in test.run_test() {
		with grid, intrinsics in device.launch_1d(num_groups, group_size) {
			with wave in grid.waves() {
				with thread in wave.threads() {
					// FIXME: nvcc / nvrtc generates incorrect code on Linux when range is used
					for i in unroll(0, wave.num_threads() as i32) {

						let iami = if thread.idx(0) == i as u32 {1} else {0};
						let x = wave.barrier_vote(iami);
						let passed = (x == (1u64 << i as u64));

						if !passed {
							thread.atomic_exch_global_u32(device_failed_flag, 5u32);
						}
					}

					if wave.barrier_vote(1) != wave.membermask() {
						thread.atomic_exch_global_u32(device_failed_flag, 6u32);
					}
				}
			}
		}

		true
	}

	// verify that every lane counts in wave barrier_count
	with device, device_memory, device_failed_flag in test.run_test() {
		with grid, intrinsics in device.launch_1d(num_groups, group_size) {
			with wave in grid.waves() {
				with thread in wave.threads() {
					for i in range(0, wave.num_threads() as i32) {

						let iami = if thread.idx(0) == i as u32 {1} else {0};
						let x = wave.barrier_count(iami);
						let passed = (x == 1);

						if !passed {
							thread.atomic_exch_global_u32(device_failed_flag, 7u32);
						}
					}

					if wave.barrier_count(1) as u32 != wave.num_threads() {
						thread.atomic_exch_global_u32(device_failed_flag, 8u32);
					}
				}
			}
		}

		true
	}


	// verify that only all threads trigger group barrier_all
	with device, device_memory, device_failed_flag in test.run_test() {
		with grid, intrinsics in device.launch_1d(num_groups, group_size) {
			with group in grid.groups() {
				with thread in group.threads() {
					for i in range(0, group.num_threads(0) as i32) {

						let iami = if thread.idx(0) == i as u32 {1} else {0};
						let x = group.barrier_all(iami);
						let passed = (x == 0);

						if !passed {
							thread.atomic_exch_global_u32(device_failed_flag, 10u32);
						}
					}

					if group.barrier_all(1) != 1 {
						thread.atomic_exch_global_u32(device_failed_flag, 11u32);
					}
				}
			}
		}

		true
	}

	// verify that any threads can trigger group barrier_any
	with device, device_memory, device_failed_flag in test.run_test() {
		with grid, intrinsics in device.launch_1d(num_groups, group_size) {
			with group in grid.groups() {
				with thread in group.threads() {
					for i in range(0, group.num_threads(0) as i32) {

						let iami = if thread.idx(0) == i as u32 {1} else {0};
						let x = group.barrier_any(iami);
						let passed = (x == 1);

						if !passed {
							thread.atomic_exch_global_u32(device_failed_flag, 12u32);
						}
					}

					if group.barrier_any(0) != 0 {
						thread.atomic_exch_global_u32(device_failed_flag, 13u32);
					}
				}
			}
		}

		true
	}

	// verify that every thread counts in group barrier_count
	with device, device_memory, device_failed_flag in test.run_test() {
		with grid, intrinsics in device.launch_1d(num_groups, group_size) {
			with group in grid.groups() {
				with thread in group.threads() {
					for i in range(0, group.num_threads(0) as i32) {

						let iami = if thread.idx(0) == i as u32 {1} else {0};
						let x = group.barrier_count(iami);
						let passed = (x == 1);

						if !passed {
							thread.atomic_exch_global_u32(device_failed_flag, 14u32);
						}
					}

					if group.barrier_count(1) as u32 != group.num_threads(0) {
						thread.atomic_exch_global_u32(device_failed_flag, 15u32);
					}
				}
			}
		}

		true
	}

	test.finish()
}
