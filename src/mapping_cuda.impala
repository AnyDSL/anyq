
static cuda_device = 0;

fn @createAccDevice() -> AccDevice {
	AccDevice {
		launch_1d: @|num_groups, group_size, body| {
			cuda_launch_1d(cuda_device, num_groups, group_size, body)
		},
		synchronize: || synchronize_cuda(cuda_device),
		alloc: |size| alloc_cuda(cuda_device, size),
		platform_device: runtime_device(1, cuda_device),
		print_i32: @|format: &[u8], arg: i32| { cuda_vprintf(format, bitcast[&[u8]](&arg)); },
		print_i32a: @|format: &[u8], args: &[i32]| { cuda_vprintf(format, bitcast[&[u8]](&args(0))); }
	}
}


fn @cuda_thread(idx: fn (i32) -> u32, body: fn (gpu_thread_context) -> ()) -> () {
	@@body(gpu_thread_context {
		idx: idx,

		atomic_load_global_i32: @|location:&mut[1]i32| cuda_atomic_add_global_i32(location, 0i32),
		atomic_load_global_u32: @|location:&mut[1]u32| cuda_atomic_add_global_u32(location, 0u32),
		atomic_load_global_u64: @|location:&mut[1]u64| cuda_atomic_add_global_u64(location, 0u64),
	
		atomic_store_global_i32: @|location:&mut[1]i32, value:i32| -> () { cuda_atomic_exch_global_i32(location, value); },
		atomic_store_global_u32: @|location:&mut[1]u32, value:u32| -> () { cuda_atomic_exch_global_u32(location, value); },
		atomic_store_global_u64: @|location:&mut[1]u64, value:u64| -> () { cuda_atomic_exch_global_u64(location, value); },

		atomic_add_global_i32: cuda_atomic_add_global_i32,
		atomic_add_global_u32: cuda_atomic_add_global_u32,
		atomic_add_global_u64: cuda_atomic_add_global_u64,

		atomic_sub_global_i32: cuda_atomic_sub_global_i32,
		atomic_sub_global_u32: cuda_atomic_sub_global_u32,
		atomic_sub_global_u64: cuda_atomic_sub_global_u64,

		atomic_and_global_i32: cuda_atomic_and_global_i32,
		atomic_and_global_u32: cuda_atomic_and_global_u32,
		atomic_and_global_u64: cuda_atomic_and_global_u64,

		atomic_or_global_i32: cuda_atomic_or_global_i32,
		atomic_or_global_u32: cuda_atomic_or_global_u32,
		atomic_or_global_u64: cuda_atomic_or_global_u64,

		atomic_xor_global_i32: cuda_atomic_xor_global_i32,
		atomic_xor_global_u32: cuda_atomic_xor_global_u32,
		atomic_xor_global_u64: cuda_atomic_xor_global_u64,

		atomic_exch_global_i32: cuda_atomic_exch_global_i32,
		atomic_exch_global_u32: cuda_atomic_exch_global_u32,
		atomic_exch_global_u64: cuda_atomic_exch_global_u64,

		atomic_min_global_i32: cuda_atomic_min_global_i32,
		atomic_min_global_u32: cuda_atomic_min_global_u32,
		atomic_min_global_u64: cuda_atomic_min_global_u64,

		atomic_max_global_i32: cuda_atomic_max_global_i32,
		atomic_max_global_u32: cuda_atomic_max_global_u32,
		atomic_max_global_u64: cuda_atomic_max_global_u64,

		atomic_cas_global_i32: cuda_atomic_cas_global_i32,
		atomic_cas_global_u32: cuda_atomic_cas_global_u32,
		atomic_cas_global_i64: cuda_atomic_cas_global_u64,

		atomic_inc_global_u32: cuda_atomic_inc_global_u32,
		atomic_dec_global_u32: cuda_atomic_dec_global_u32,

		yield: @|| cuda_threadfence() //cuda_nanosleep(0u32)
	});
}

fn @cuda_subwarp(idx: fn () -> u32, membermask: u32, num_threads: u32, body: fn (gpu_wave_context) -> ()) -> () {
	let thread_idx = @|i| match i { 0 => cuda_laneid(), _ => 0u32 };

	@@body(gpu_wave_context{
		idx: idx,

		membermask: @|| membermask as u64,

		threads: @|body| cuda_thread(thread_idx, body),

		num_threads: @|| num_threads,

		barrier: @|| cuda_warp_sync(membermask),
		barrier_all: @|predicate| cuda_warp_sync_all(membermask, predicate),
		barrier_any: @|predicate| cuda_warp_sync_any(membermask, predicate),
		barrier_count: @|predicate| cuda_popc_u32(cuda_warp_sync_vote(membermask, predicate)),
		barrier_vote: @|predicate| cuda_warp_sync_vote(membermask, predicate) as u64,

		// activemask: cuda_warp_activemask,

		shfl_i32: @|x:i32, src_lane:i32, width:u32| cuda_warp_shfl_i32(membermask, x, src_lane, width as i32),
		shfl_u32: @|x:u32, src_lane:i32, width:u32| cuda_warp_shfl_u32(membermask, x, src_lane, width as i32),
		// shfl_i64: @|x:i64, src_lane:i32, width:u32| cuda_warp_shfl_i64(membermask, x, src_lane, width as i32),
		// shfl_u64: @|x:u64, src_lane:i32, width:u32| cuda_warp_shfl_u64(membermask, x, src_lane, width as i32),
		// shfl_f32: @|x:f32, src_lane:i32, width:u32| cuda_warp_shfl_f32(membermask, x, src_lane, width as i32),
		// shfl_f64: @|x:f64, src_lane:i32, width:u32| cuda_warp_shfl_f64(membermask, x, src_lane, width as i32),

		shfl_up_i32: @|x:i32, delta:u32, width:u32| cuda_warp_shfl_up_i32(membermask, x, delta, width as i32),
		shfl_up_u32: @|x:u32, delta:u32, width:u32| cuda_warp_shfl_up_u32(membermask, x, delta, width as i32),
		// shfl_up_i64: @|x:i64, delta:u32, width:u32| cuda_warp_shfl_up_i64(membermask, x, delta, width as i32),
		// shfl_up_u64: @|x:u64, delta:u32, width:u32| cuda_warp_shfl_up_u64(membermask, x, delta, width as i32),
		// shfl_up_f32: @|x:f32, delta:u32, width:u32| cuda_warp_shfl_up_f32(membermask, x, delta, width as i32),
		// shfl_up_f64: @|x:f64, delta:u32, width:u32| cuda_warp_shfl_up_f64(membermask, x, delta, width as i32),

		shfl_down_i32: @|x:i32, delta:u32, width:u32| cuda_warp_shfl_down_i32(membermask, x, delta, width as i32),
		shfl_down_u32: @|x:u32, delta:u32, width:u32| cuda_warp_shfl_down_u32(membermask, x, delta, width as i32),
		// shfl_down_i64: @|x:i64, delta:u32, width:u32| cuda_warp_shfl_down_i64(membermask, x, delta, width as i32),
		// shfl_down_u64: @|x:u64, delta:u32, width:u32| cuda_warp_shfl_down_u64(membermask, x, delta, width as i32),
		// shfl_down_f32: @|x:f32, delta:u32, width:u32| cuda_warp_shfl_down_f32(membermask, x, delta, width as i32),
		// shfl_down_f64: @|x:f64, delta:u32, width:u32| cuda_warp_shfl_down_f64(membermask, x, delta, width as i32),

		shfl_bfly_i32: @|x:i32, lane_mask:i32, width:u32| cuda_warp_shfl_xor_i32(membermask, x, lane_mask, width as i32),
		shfl_bfly_u32: @|x:u32, lane_mask:i32, width:u32| cuda_warp_shfl_xor_u32(membermask, x, lane_mask, width as i32),
		// shfl_bfly_i64: @|x:i64, lane_mask:i32, width:u32| cuda_warp_shfl_xor_i64(membermask, x, lane_mask, width as i32),
		// shfl_bfly_u64: @|x:u64, lane_mask:i32, width:u32| cuda_warp_shfl_xor_u64(membermask, x, lane_mask, width as i32),
		// shfl_bfly_f32: @|x:f32, lane_mask:i32, width:u32| cuda_warp_shfl_xor_f32(membermask, x, lane_mask, width as i32),
		// shfl_bfly_f64: @|x:f64, lane_mask:i32, width:u32| cuda_warp_shfl_xor_f64(membermask, x, lane_mask, width as i32),

		// match_any_i32: @|x:i32| cuda_warp_match_any_i32(membermask, x),
		// match_any_u32: @|x:u32| cuda_warp_match_any_u32(membermask, x),
		// match_any_i64: @|x:i64| cuda_warp_match_any_i64(membermask, x),
		// match_any_u64: @|x:u64| cuda_warp_match_any_u64(membermask, x),
		// match_any_f32: @|x:f32| cuda_warp_match_any_f32(membermask, x),
		// match_any_f64: @|x:f64| cuda_warp_match_any_f64(membermask, x),

		// match_all_i32: @|x:i32, predicate:&mut i32| cuda_warp_match_all_i32(membermask, x, predicate),
		// match_all_u32: @|x:u32, predicate:&mut i32| cuda_warp_match_all_u32(membermask, x, predicate),
		// match_all_i64: @|x:i64, predicate:&mut i32| cuda_warp_match_all_i64(membermask, x, predicate),
		// match_all_u64: @|x:u64, predicate:&mut i32| cuda_warp_match_all_u64(membermask, x, predicate),
		// match_all_f32: @|x:f32, predicate:&mut i32| cuda_warp_match_all_f32(membermask, x, predicate),
		// match_all_f64: @|x:f64, predicate:&mut i32| cuda_warp_match_all_f64(membermask, x, predicate),

		lanemask: @|| cuda_lanemask() as u64,
		lanemask_le: @|| cuda_lanemask_le() as u64,
		lanemask_lt: @|| cuda_lanemask_lt() as u64,
		lanemask_ge: @|| cuda_lanemask_ge() as u64,
		lanemask_gt: @|| cuda_lanemask_gt() as u64
	});
}

fn @cuda_block(idx: fn (i32) -> u32, thread_idx: fn (i32) -> u32, num_threads: fn (i32) -> u32, warp_size: u32, body: fn (gpu_group_context) -> ()) -> () {
	let linear_thread_idx = @|| {
		(thread_idx(2) * num_threads(1) + thread_idx(1)) * num_threads(0) + thread_idx(0)
	};

	let warp_idx = @|| {
		linear_thread_idx() / warp_size
	};

	let num_warps = @|| ((num_threads(0) * num_threads(1) * num_threads(2)) + warp_size - 1u32) / warp_size;

	@@body(gpu_group_context {
		idx: idx,
		waves: @|body| cuda_subwarp(warp_idx, -1 as u32, warp_size, body),
		threads: @|body| cuda_thread(thread_idx, body),
		num_waves: num_warps,
		num_threads: num_threads,
		barrier: cuda_block_sync,
		barrier_all: cuda_block_sync_all,
		barrier_any: cuda_block_sync_any,
		barrier_count: cuda_block_sync_count
	});
}

fn cuda_launch(device: i32, grid_dim: (i32, i32, i32), block_dim: (i32, i32, i32), wrap_index: index_wrapper, wrap_dim: dim_wrapper, body: fn (gpu_grid_context, Intrinsics) -> ()) -> () {
	// TODO: assert(warp_size == 32)
	let warp_size = 32u32;

	let num_threads_per_block = wrap_dim(@|i| {
		match i {
			0 => if ?block_dim(0) { block_dim(0) as u32 } else { cuda_blockDim_x() as u32 },
			1 => if ?block_dim(1) { block_dim(1) as u32 } else { cuda_blockDim_y() as u32 },
			2 => if ?block_dim(2) { block_dim(2) as u32 } else { cuda_blockDim_z() as u32 },
			_ => 1u32
		}
	});

	let num_warps_per_block = @|| ((num_threads_per_block(0) * num_threads_per_block(1) * num_threads_per_block(2)) + warp_size - 1u32) / warp_size;

	let num_blocks = wrap_dim(@|i| {
		match i {
			0 => if ?grid_dim(0) { grid_dim(0) as u32 } else { cuda_gridDim_x() as u32 },
			1 => if ?grid_dim(1) { grid_dim(1) as u32 } else { cuda_gridDim_y() as u32 },
			2 => if ?grid_dim(1) { grid_dim(2) as u32 } else { cuda_gridDim_z() as u32 },
			_ => 1u32
		}
	});

	let num_warps = @|| (num_blocks(0) * num_blocks(1) * num_blocks(2)) * num_warps_per_block();

	let num_threads = @|i| num_blocks(i) * num_threads_per_block(i);

	let block_idx = wrap_index(@|i| {
		match i { 0 => cuda_blockIdx_x() as u32, 1 => cuda_blockIdx_y() as u32, 2 => cuda_blockIdx_z() as u32, _ => 0u32 }
	});

	let linear_block_idx = @|| (block_idx(2) * num_blocks(1) + block_idx(1)) * num_blocks(0) + block_idx(0);

	let thread_idx = wrap_index(@|i| {
		match i { 0 => cuda_threadIdx_x() as u32, 1 => cuda_threadIdx_y() as u32, 2 => cuda_threadIdx_z() as u32, _ => 0u32 }
	});

	let global_thread_idx = @|i| block_idx(i) * num_threads_per_block(i) + thread_idx(i);

	let linear_thread_idx = @|| (thread_idx(2) * num_threads_per_block(1) + thread_idx(1)) * num_threads_per_block(0) + thread_idx(0);

	let global_warp_idx = @|| linear_block_idx() * num_warps_per_block() + linear_thread_idx() / warp_size;

	cuda(device, (grid_dim(0) * block_dim(0), grid_dim(1) * block_dim(1), grid_dim(2) * block_dim(2)), (block_dim(0), block_dim(1), block_dim(2)), @|| @@body(gpu_grid_context {
		device: device,
		groups: @|body| cuda_block(block_idx, thread_idx, num_threads_per_block, warp_size, body),
		waves: @|body| cuda_subwarp(global_warp_idx, -1 as u32, warp_size, body),
		threads: @|body| cuda_thread(global_thread_idx, body),
		num_groups: num_blocks,
		num_waves: num_warps,
		num_threads: num_threads
	}, cuda_intrinsics));
}

fn cuda_launch_1d(device: i32, grid_dim: i32, block_dim: i32, body: fn (gpu_grid_context, Intrinsics) -> ()) -> () {
	@@cuda_launch(device, (grid_dim, 1, 1), (block_dim, 1, 1), wrap_index_1d, wrap_dim_1d, body)
}

fn cuda_launch_2d(device: i32, grid_dim: (i32, i32), block_dim: (i32, i32), body: fn (gpu_grid_context, Intrinsics) -> ()) -> () {
	@@cuda_launch(device, (grid_dim(0), grid_dim(1), 1), (block_dim(0), block_dim(1), 1), wrap_index_2d, wrap_dim_2d, body)
}

fn cuda_launch_3d(device: i32, grid_dim: (i32, i32, i32), block_dim: (i32, i32, i32), body: fn (gpu_grid_context, Intrinsics) -> ()) -> () {
	@@cuda_launch(device, grid_dim, block_dim, wrap_index_3d, wrap_dim_3d, body)
}
