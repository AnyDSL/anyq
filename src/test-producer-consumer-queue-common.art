
// mod queue_tests {
	// use super::self;
	// use super::range;
	// use super::sizeof;
	// use super::bitcast;
	// use super::div_up;
	// use super::AccDevice;
	// use super::createAccDevice;
	// use super::ProducerConsumerQueue;
	// use super::QueueElementType;
	// use super::createConcurrentProducerConsumerQueue;
	// use super::createBaseTest;

	struct QueueTest[T] {
		run_test: fn(fn(ProducerConsumerQueue[T], &mut addrspace(1) [i8], &mut addrspace(1) u32) -> bool) -> fn(i32) -> (),
		finish: fn() -> i32
	}
	
	fn createQueueTest[T](device: AccDevice, element_type: QueueElementType[T], additional_mem: i64) -> QueueTest[T] {
		let test = createBaseTest(device, additional_mem);
	
		QueueTest[T] {
			run_test = @|body|@|queue_size| {
				for device_memory, device_failed_flag in test.run_test() {
					let queue = createConcurrentProducerConsumerQueue[T](device, element_type, queue_size);
	
					let block_dim = 256;
					let num_blocks = (queue_size + block_dim - 1) / block_dim;
	
					for grid in device.launch_1d(num_blocks, block_dim) {
						queue.reset(grid);
					}
	
					let cpu_result = body(queue, device_memory, device_failed_flag);
	
					for grid in device.launch_1d(num_blocks, block_dim) {
						queue.validate(device_failed_flag, grid);
					}
	
					device.synchronize();
					queue.release();
	
					cpu_result
				}
			},
	
			finish = @|| {
				test.finish()
			}
		}
	}


	struct QueueTestElement[T] {
		element_type: QueueElementType[T],
		generateElement: fn(u32) -> T,
		checkElement: fn(T, u32) -> bool
	}

	fn indexTestElement() = QueueTestElement[u32] {
		element_type = indexQueueElementType(),
		generateElement = @|id:u32| id,
		checkElement = @|el:u32, check:u32| el == check
	};

	type GenericElementSimple = i64;

	fn genericTestElementSimple() = QueueTestElement[GenericElementSimple] {
		element_type = genericQueueElementType[GenericElementSimple](),
		generateElement = @|id:u32| -> GenericElementSimple { id as i64 },
		checkElement = @|el:GenericElementSimple, check:u32| el == check as i64
	};

	struct GenericElementStruct {
		payload: bool,
		blub: u32
	}

	fn genericTestElementStruct() = QueueTestElement[GenericElementStruct] {
		element_type = genericQueueElementType[GenericElementStruct](),
		generateElement = @|id:u32| GenericElementStruct { payload = id % 3 == 0, blub = id },
		checkElement = @|el:GenericElementStruct, check:u32| el.blub == check
	};

	struct GenericElementComplexStruct {
		payload: [u32 * 7],
		blub: u32
	}

	fn genericTestElementComplexStruct() = QueueTestElement[GenericElementComplexStruct] {
		element_type = genericQueueElementType[GenericElementComplexStruct](),
		generateElement = @|id:u32| GenericElementComplexStruct { payload = [0; 7], blub = id },
		checkElement = @|el:GenericElementComplexStruct, check:u32| el.blub == check
	};


	fn push_and_then_pop_queue_test[T](test_case: QueueTestElement[T]) -> i32 {
		let device = createAccDevice();

		let num_elements = 20;
		let queue_size = num_elements;
		let queue_test = createQueueTest(device, test_case.element_type, (num_elements + 2) as i64 * sizeof[u32]());
		let block_dim = 8;

		for queue, device_memory, device_failed_flag in queue_test.run_test(queue_size) {
			// keep track of which slots have been handed out to whom.
			let pushed_buffer = bitcast[&mut addrspace(1) [i32]](device_memory);
			let num_pushed = bitcast[&mut addrspace(1) i32](&mut pushed_buffer(num_elements + 0));
			let num_popped = bitcast[&mut addrspace(1) i32](&mut pushed_buffer(num_elements + 1));

			device.print_i32("initialize debug pushed_buffer ...\n", 0);

			for grid in device.launch_1d(div_up(num_elements + 2, block_dim), block_dim) {
				for thread in grid.threads() {
					if thread.idx(0) as i32 >= num_elements {
						if thread.idx(0) as i32 < num_elements + 2 {
							pushed_buffer(thread.idx(0)) = 0;
						}
					}
					else {
						thread.atomic_store_global_i32(&mut pushed_buffer(thread.idx(0)), -1);
					}
				}
			}

			device.synchronize();

			device.print_i32("concurrent push until full ...\n", 0);

			// concurrent push until full, verify that each element is handed out exactly once
			for grid in device.launch_1d(42, block_dim) {
				for thread in grid.threads() {
					while (
						if for i in queue.push(thread) {
							let old = thread.atomic_exch_global_i32(&mut pushed_buffer(i), thread.idx(0) as i32);

							if (old != -1) {
								device.print_2xi32("ERROR: queue element %u handed out more than once! (previously to %u)\n", i as i32, old);
								thread.atomic_store_global_u32(device_failed_flag, -1);
							}

							test_case.generateElement(thread.idx(0))
						} > 0 {
							thread.atomic_add_global_i32(num_pushed, 1);
							true
						}
						else {
							thread.atomic_load_global_i32(num_pushed) < queue_size
						}
					) {}
				}
			}

			device.synchronize();

			for grid in device.launch_1d(1, block_dim) {
				for thread in grid.threads() {
					if thread.idx(0) == 0 {
						device.print_i32("queue size: %d\n", queue.size(thread));
					}
				}
			}

			// check that all elements have been handed out
			for grid in device.launch_1d(div_up(num_elements, block_dim), block_dim) {
				for thread in grid.threads() {
					if thread.idx(0) < num_elements as u32 {
						device.print_2xi32("pushed_buffer(%d) = %d\n", thread.idx(0) as i32, pushed_buffer(thread.idx(0)));
						if thread.atomic_load_global_i32(&mut pushed_buffer(thread.idx(0))) < 0 {
							device.print_i32("ERROR: queue element %u has been skipped!\n", thread.idx(0) as i32);
							thread.atomic_or_global_u32(device_failed_flag, 1 << 1);
						}
					}
				}
			}

			device.synchronize();
			device.print_i32("concurrent pop until empty ...\n", 0);

			// concurrent pop until empty, verify that each element comes from the correct slot
			for grid in device.launch_1d(42, block_dim) {
				for thread in grid.threads() {
					while (
						if for el, i in queue.pop(thread) {
							device.print_2xi32("check pushed_buffer(%d) for %d\n", i as i32, bitcast[u32](el) as i32);

							if i < num_elements as u32 {

							let check = thread.atomic_exch_global_i32(&mut pushed_buffer(i), -1);
							if check < 0 {
								device.print_i32("ERROR: popped queue element %d was not used in pushed_buffer!\n", i as i32);
							}

							if !test_case.checkElement(el, check as u32) {
								device.print_2xi32("ERROR: popped queue element %d does not match reference value (%d)!\n", i as i32, check);
								//device.print_2xi32("Expected %d - found %d\n", [check as i32, bitcast[u32](el) as i32]);
								thread.atomic_store_global_u32(device_failed_flag, -1);
							}

							}
						} > 0 {
							thread.atomic_add_global_i32(num_popped, 1);
							true
						}
						else {
							thread.atomic_load_global_i32(num_popped) < queue_size
						}
					) {}
				}
			}

			device.synchronize();

			device.print_i32("check that all elements have been popped ...\n", 0);

			// check that all elements have been popped
			for grid in device.launch_1d(div_up(num_elements, block_dim), block_dim) {
				for thread in grid.threads() {
					if thread.idx(0) as i32 < num_elements {
						if pushed_buffer(thread.idx(0)) != -1 {
							device.print_i32("ERROR: queue element %u has not been popped!\n", thread.idx(0) as i32);
							thread.atomic_store_global_u32(device_failed_flag, -1);
						}
					}

					if thread.idx(0) == 0 {
						let num_pushed_val = thread.atomic_load_global_i32(num_pushed);
						let num_popped_val = thread.atomic_load_global_i32(num_popped);

						if num_pushed_val != num_elements {
							device.print_2xi32("pushed only %d elements out of %d\n", num_pushed_val, num_elements);
							if num_pushed_val != queue_size {
								thread.atomic_or_global_u32(device_failed_flag, 1 << 5);
							}
						}

						if num_popped_val != num_elements {
							device.print_2xi32("popped only %d elements out of %d\n", num_popped_val, num_elements);
							if num_popped_val != queue_size {
								thread.atomic_or_global_u32(device_failed_flag, 1 << 6);
							}
						}
					}
				}
			}

			true
		}

		queue_test.finish()
	}

	fn concurrent_push_pop_queue_test[T](num_elements: i32, test_case: QueueTestElement[T]) -> i32 {
		let device = createAccDevice();

		let queue_test = createQueueTest(device, test_case.element_type, (num_elements as i64 + 4) * sizeof[u32]());
		let block_dim = 256;

		for queue, device_memory, device_failed_flag in queue_test.run_test(num_elements) {
			// keep track of which slots have been handed out to whom.
			let pushed_buffer = bitcast[&mut addrspace(1) [u32]](device_memory);
			let num_pushed = bitcast[&mut addrspace(1) i32](&mut pushed_buffer(num_elements + 0));
			let num_not_pushed = bitcast[&mut addrspace(1) i32](&mut pushed_buffer(num_elements + 1));
			let num_popped = bitcast[&mut addrspace(1) i32](&mut pushed_buffer(num_elements + 2));
			let num_not_popped = bitcast[&mut addrspace(1) i32](&mut pushed_buffer(num_elements + 3));

			for grid in device.launch_1d(div_up(num_elements + 4, block_dim), block_dim) {
				for thread in grid.threads() {
					if thread.idx(0) as i32 >= num_elements {
						if thread.idx(0) as i32 < num_elements + 4 {
							pushed_buffer(thread.idx(0)) = 0;
						}
					}
					else {
						pushed_buffer(thread.idx(0)) = -1;
					}
				}
			}

			device.synchronize();

			// concurrent push and pop, verify that each element is handed out exactly once and comes from the correct slot
			for grid in device.launch_1d(42, block_dim) {
				for thread in grid.threads() {
					let mut rand_state = rand::xorseed32(thread.idx(0));

					for i in range(0, 10) {
						if rand_state < (-1 as u32) / 2 {
							// push
							if for i in queue.push(thread) {
								let old = thread.atomic_exch_global_u32(&mut pushed_buffer(i), thread.idx(0));

								if (old != -1) {
									device.print_i32("ERROR: queue element %u handed out more than once!\n", i as i32);
									thread.atomic_store_global_u32(device_failed_flag, -1);
								}

								test_case.generateElement(thread.idx(0))
							} > 0 {
								thread.atomic_add_global_i32(num_pushed, 1);
							}
							else {
								thread.atomic_add_global_i32(num_not_pushed, 1);
							}
						}
						else {
							// pop
							if for el, i in queue.pop(thread) {
								let check = thread.atomic_exch_global_u32(&mut pushed_buffer(i), -1);
			
								if !test_case.checkElement(el, check) {
									device.print_i32("ERROR: popped queue element %u does not match reference value!\n", i as i32);
									thread.atomic_store_global_u32(device_failed_flag, -1);
								}
							} > 0 {
								thread.atomic_add_global_i32(num_popped, 1);
							}
							else {
								thread.atomic_add_global_i32(num_not_popped, 1);
							}
						}

						rand_state = rand::xorshift32(rand_state);
					}
				}
			}

			device.synchronize();

			// pop remaining elements until empty, verify that each element comes from the correct slot
			for grid in device.launch_1d(42, block_dim) {
				for thread in grid.threads() {
					while (for el, i in queue.pop(thread) {
						let check = thread.atomic_exch_global_u32(&mut pushed_buffer(i), -1);

						if !test_case.checkElement(el, check) {
							device.print_i32("ERROR: popped queue element %u does not match reference value!\n", i as i32);
							thread.atomic_store_global_u32(device_failed_flag, -1);
						}
					}) > 0 {};
				}
			}

			device.synchronize();

			// check that all elements have been popped
			for grid in device.launch_1d(div_up(num_elements, block_dim), block_dim) {
				for thread in grid.threads() {
					if thread.idx(0) as i32 < num_elements {
						if pushed_buffer(thread.idx(0)) != -1 {
							device.print_i32("ERROR: queue element %u has not been popped!\n", thread.idx(0) as i32);
							thread.atomic_store_global_u32(device_failed_flag, -1);
						}
					}

					if thread.idx(0) == 0 {
						device.print_i32("num_pushed = %d\n", *num_pushed);
						device.print_i32("num_popped = %d\n", *num_popped);
						device.print_i32("num_not_pushed = %d\n", *num_not_pushed);
						device.print_i32("num_not_popped = %d\n", *num_not_popped);
					}
				}
			}

			true
		}

		queue_test.finish()
	}
// }
