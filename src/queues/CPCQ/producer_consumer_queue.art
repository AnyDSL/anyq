mod CPCQ {
	struct Queue {
		size: i32,
		head: u32,
		tail: u32
	}

	struct Element[T] {
		lock: u32,
		data: T
	}
}

struct QueueElement[T] {
	clear: fn() -> (),
	is_free: fn() -> bool,
	store: fn(fn() -> T, thread_context) -> (),
	load: fn(fn(T) -> (), thread_context) -> (),
	debug_print: fn(AccDevice) -> ()
}

struct QueueElementType[T] {
	buffer_size: fn(i32) -> i64,
	buffer_alignment: fn() -> i64,
	buffer_element: fn(&mut addrspace(1) [u8], u32) -> QueueElement[T]
}

// note (cc < 7.0): threads within the same warp must only ever either enqueue or dequeue stuff concurrently
//                  this is fine as long as a warp only ever acts as either a producer or consumer at a time
fn @createConcurrentProducerConsumerQueue[T](device: AccDevice, element_type: QueueElementType[T], num_elements: i32) -> ProducerConsumerQueue[T] {
	let buffer_size = element_type.buffer_size(num_elements);
	let buffer_alignment = element_type.buffer_alignment();

	let buffer_data_offset = round_up_i64(sizeof[CPCQ::Queue](), buffer_alignment);

	let queue_device_state_alloc = device.alloc(buffer_data_offset + buffer_size);
	let queue_device_memory = queue_device_state_alloc.data as &mut addrspace(1) [u8];

	let queue = &mut queue_device_memory(0) as &mut addrspace(1) CPCQ::Queue;
	let buffer = &mut queue_device_memory(buffer_data_offset) as &mut addrspace(1) [u8];

	let buffer_element = @|i:u32| -> QueueElement[T] { element_type.buffer_element(buffer, i) };

	ProducerConsumerQueue[T] {
		push = @|source| @|thread| {
			let current_size = thread.atomic_load_global_i32(queue.size, memory_order::relaxed);
			if current_size >= num_elements {
				0
			}
			else {
				let new_size = thread.atomic_add_global_i32(queue.size, 1, memory_order::relaxed);
				for anyq_verbose() {
					device.print_3xi32("%d | QUEUE: reserve for push %d -> %d\n", thread.gid() as i32, current_size, new_size);
				}

				if new_size >= num_elements {
					for anyq_verbose() {
						device.print_2xi32("%d | QUEUE: reject push %d\n", thread.gid() as i32, new_size);
					}

					thread.atomic_sub_global_i32(queue.size, 1, memory_order::relaxed);

					0
				}
				else {
					let i = thread.atomic_inc_global_u32(queue.tail, (num_elements - 1) as u32);
					for anyq_verbose() {
						device.print_2xi32("%d | QUEUE: move tail %d\n", thread.gid() as i32, i as i32);
					}

					buffer_element(i).store(source, thread);

					1
				}
			}
		},

		pop = @|sink| @|thread| {
			let current_size = thread.atomic_load_global_i32(queue.size, memory_order::relaxed);
			if current_size <= 0 {
				0
			}
			else {
				let available = thread.atomic_sub_global_i32(queue.size, 1, memory_order::relaxed);
				for anyq_verbose() {
					device.print_3xi32("%d | QUEUE: allocate for pop %d -> %d\n", thread.gid() as i32, current_size, available);
				}

				if available <= 0 {
					for anyq_verbose() {
						device.print_2xi32("%d | QUEUE: reject pop %d\n", thread.gid() as i32, available);
					}

					thread.atomic_add_global_i32(queue.size, 1, memory_order::relaxed);

					0
				}
				else {
					let i = thread.atomic_inc_global_u32(queue.head, (num_elements - 1) as u32);
					for anyq_verbose() {
						device.print_2xi32("%d | QUEUE: move head %d\n", thread.gid() as i32, i as i32);
					}

					buffer_element(i).load(sink, thread);

					1
				}
			}
		},

		size = @|thread| {
			thread.atomic_load_global_i32(queue.size, memory_order::relaxed)
		},

		reset = @|grid| {
			for thread in grid.threads() {
				if thread.idx(0) == 0 {
					queue.size = 0;
					queue.head = 0;
					queue.tail = 0;
				}

				for i in range_step(thread.idx(0) as i32, num_elements, grid.num_threads(0) as i32) {
					buffer_element(i as u32).clear();
				}
			}
		},

		validate = @|corrupted, grid| {
			for thread in grid.threads() {
				let idx = thread.idx(0);

				if idx == 0 {
					if (queue.size != 0) {
						device.print_i32("VALIDATION ERROR: queue size (%d) is not zero!\n", queue.size);
						thread.atomic_store_global_u32(corrupted, 1, memory_order::relaxed);
					}
				}

				if idx < num_elements as u32 {
					let element = buffer_element(idx);
					if !element.is_free() {
						thread.atomic_store_global_u32(corrupted, 1, memory_order::relaxed);
						element.debug_print(device);
					}
				}
			}
		},

		release = @|| {
			release(queue_device_state_alloc);
		}
	}
}

fn @genericQueueElementType[T]() {
	let element_alignment = alignof[CPCQ::Element[T]]();
	let element_size = round_up_i64(sizeof[CPCQ::Element[T]](), element_alignment);

	QueueElementType[T] {
		buffer_size = @|num_elements| num_elements as i64 * element_size,
		buffer_alignment = @|| element_alignment,
		buffer_element = @|buffer, i| {

			let element = &mut (buffer as &mut addrspace(1) [CPCQ::Element[T]])(i);

			QueueElement[T] {
				clear = @|| element.lock = 0,
				is_free = @|| element.lock == 0,
				load = @|sink, thread| {
					thread.wait(@|| thread.atomic_cas_global_u32_weak(element.lock, 2, 3, memory_order::acquire, memory_order::relaxed).1, "wait for element lock to read");

					sink(element.data);

					thread.atomic_store_global_u32(element.lock, 0, memory_order::release);
				},
				store = @|source, thread| {
					thread.wait(@|| thread.atomic_cas_global_u32_weak(element.lock, 0, 1, memory_order::acquire, memory_order::relaxed).1, "wait for element lock to write");

					element.data = source();

					thread.atomic_store_global_u32(element.lock, 2, memory_order::release);
				},
				debug_print = @|device| {
					device.print_2xi32("VALIDATION ERROR: inconsistent queue state: buffer[%d] = %d\n", i as i32, element.lock as i32);
				}
			}
		}
	}
}

fn @indexQueueElementType() = QueueElementType[u32] {
	buffer_size = @|num_elements| num_elements as i64 * sizeof[u32](),
	buffer_alignment = @|| alignof[u32](),
	buffer_element = @|buffer, i| {
		let FREE = -1 as u32;

		let element = &mut (buffer as &mut addrspace(1) [u32])(i);

		QueueElement[u32] {
			clear = @|| *element = FREE,
			is_free = @|| *element == FREE,
			load = @|sink, thread| {
				thread.wait(@|| {
					let el = thread.atomic_exch_global_u32(element, FREE, memory_order::relaxed);
					if el != FREE {
						sink(el);
						true
					}
					else {
						false
					}
				}, "wait for element");
			},
			store = @|source, thread| {
				let value = source();
				thread.wait(@|| thread.atomic_cas_global_u32_weak(element, FREE, value, memory_order::relaxed, memory_order::relaxed).1, "wait for a successful indexQueueElementType.store()");
			},
			debug_print = @|device| {
				device.print_2xi32("VALIDATION ERROR: inconsistent queue state: buffer[%d] = %d\n", i as i32, *element as i32);
			}
		}
	}
};

fn @createConcurrentProducerConsumerIndexQueue(device: AccDevice, num_elements: i32) = createConcurrentProducerConsumerQueue[u32](device, indexQueueElementType(), num_elements);
fn @createConcurrentProducerConsumerQueueGeneric[T](device: AccDevice, num_elements: i32) = createConcurrentProducerConsumerQueue[T](device, genericQueueElementType[T](), num_elements);
