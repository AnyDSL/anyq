// AnyQ wrapper for reference implementation published with
// Chaoran Yang and John Mellor-Crummey. 2016. A wait-free queue as fast as fetch-and-add.
// In Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP '16), pages 1â€“13.
// https://doi.org/10.1145/2851141.2851168



type PADDING = [u8*4];


struct enq_t {
  id: i32,
  pad: PADDING,
  val: u64, // void*
}

struct deq_t {
  id: i32,
  idx: i32,
}

struct cell_t {
  val: u64, // void*
  enq: &mut enq_t,
  deq: &mut enq_t,
  pad: [u64*5], // void*[5]
}

static WFQUEUE_NODE_SIZE = ((1 << 10) - 2);

struct node_t {
  next: u64, // &mut node_t
  id: i32,
  pad: PADDING,
  cells: [cell_t*1022],
}


struct queue_t {
  /**
   * Index of the next position for enqueue.
   */
  // DOUBLE_CACHE_ALIGNED
  Ei: i32,

  /**
   * Index of the next position for dequeue.
   */
  // DOUBLE_CACHE_ALIGNED
  Di: i32,

  /**
   * Index of the head of the queue.
   */
  // DOUBLE_CACHE_ALIGNED
  Hi: i32,

  pad1: PADDING,

  /**
   * Pointer to the head node of the queue.
   */
  Hp: &mut node_t,

  /**
   * Number of processors.
   */
  nprocs: i32,

  pad2: PADDING,
}

struct handle_t {
  /**
   * Pointer to the next handle.
   */
  next: u64, // &mut handle_t

  /**
   * Hazard pointer.
   */
  Hp: &mut node_t,

  /**
   * Pointer to the node for enqueue.
   */
  Ep: &mut node_t,

  /**
   * Pointer to the node for dequeue.
   */
  Dp: &mut node_t,

  /**
   * Enqueue request.
   */
  Er: enq_t,

  /**
   * Dequeue request.
   */
  Dr: deq_t,

  /**
   * Handle of the next enqueuer to help.
   */
  Eh: u64, // &mut handle_t

  Ei: i32,

  pad1: PADDING,

  /**
   * Handle of the next dequeuer to help.
   */
  Dh: u64, // &mut handle_t

  /**
   * Pointer to a spare node to use, to speedup adding a new node.
   */
  spare: &mut node_t,

  /**
   * Count the delay rounds of helping another dequeuer.
   */
  delay: i32,

  pad2: PADDING,
}


struct wfqueue_t
{
  q: queue_t,
  size: i32,
  tail: &mut handle_t,
  h: &mut [handle_t],
}

type WFQHandle = &mut wfqueue_t;


#[import(cc = "C")] fn wfqueue_create(_nprocs: i32, _out_handle: &mut WFQHandle) -> i32;
#[import(cc = "C")] fn wfqueue_size(_queue: WFQHandle) -> i32;
#[import(cc = "C")] fn wfqueue_destroy(_queue: WFQHandle) -> i32;
#[import(cc = "C")] fn wfqueue_try_enqueue_u32(_: WFQHandle, _id: i32, _value: u32) -> i32;
#[import(cc = "C")] fn wfqueue_try_dequeue_u32(_: WFQHandle, _id: i32, _out_value: &mut u32) -> i32;

#[import(cc = "C")] fn enqueue(_q: &mut queue_t, _th: &mut handle_t, _value: u64) -> i32;
#[import(cc = "C")] fn dequeue(_q: &mut queue_t, _th: &mut handle_t) -> u64;

#[import(cc = "C")] fn find_cell(_n: &mut &mut node_t, _i: i32, _th: &mut handle_t) -> &mut cell_t;


static default_num_handles = 128;


static EMPTY:u64 = 0; // void*
static BOT:u64 = 0;
static TOP:u64 = -1 as u64;

static MAX_PATIENCE = 10;


fn new_node(device: AccDevice) -> &mut node_t {
	let s = sizeof[node_t]();
	let b = device.alloc(s);
	for i in range(0, s as i32) {
		b.data(i) = 0;
	}
	b.data as &mut node_t
}

fn release_node(node: &mut node_t) -> () {
	runtime_release(0, node as &mut [i8]);
}

fn wfqueue_create_internal(device: AccDevice, nprocs: i32, queue_ptr: &mut &mut wfqueue_t) -> i32
{
	//device.print_3xi32("sizeof(wfqueue_t): %d\nsizeof(queue_t): %d\nsizeof(handle_t): %d\n", sizeof[wfqueue_t]() as i32, sizeof[queue_t]() as i32, sizeof[handle_t]() as i32);
	//device.print_3xi32("sizeof(enq_t): %d\nsizeof(deq_t): %d\nsizeof(node_t): %d\n", sizeof[enq_t]() as i32, sizeof[deq_t]() as i32, sizeof[node_t]() as i32);

	let queue_size = sizeof[wfqueue_t]();

	let handles_offset = round_up_i64(queue_size, 64);
	let handles_size = nprocs as i64 * sizeof[handle_t]();

	let dev_queue_buffer = device.alloc(handles_offset + handles_size);
	let dev_data = dev_queue_buffer.data;

	let queue = &dev_data(0) as &mut wfqueue_t;
	let handles = &dev_data(handles_offset) as &mut [handle_t];

	//queue_init(queue.q, nprocs);
	queue.q.Hi = 0;
	queue.q.Hp = new_node(device);

	queue.q.Ei = 1;
	queue.q.Di = 1;

	queue.q.nprocs = nprocs;

	queue.size = 0;
	queue.h = handles;

	for i in range(0, nprocs) {
		//queue_register(queue.q, &mut queue.tail, &mut queue.h(i), i);
		let th = &mut (*queue).h(i);

		(*th).next = 0;
		(*th).Hp = 0 as &mut node_t;
		(*th).Ep = queue.q.Hp;
		(*th).Dp = queue.q.Hp;

		(*th).Er.id = 0;
		(*th).Er.val = BOT;
		(*th).Dr.id = 0;
		(*th).Dr.idx = -1;

		(*th).Ei = 0;
		(*th).spare = new_node(device);

		(*th).next = &mut queue.h(i + 1) as u64;
		(*th).Eh = th.next;
		(*th).Dh = th.next;
	}

	let last_th = &mut queue.h(queue.q.nprocs - 1);
	(*last_th).next = &mut queue.h(0) as u64;
	(*last_th).Eh = last_th.next;
	(*last_th).Dh = last_th.next;

	(*queue).tail = &mut queue.h(0);

	*queue_ptr = queue;

	1
}

fn wfqueue_destroy_internal(queue: &mut wfqueue_t) -> i32
{
	//queue_t* q = &queue->q;
	let mut n:u64 = queue.q.Hp as u64;

	while (n != 0) {
		let tmp = (n as &mut node_t).next;
		release_node(n as &mut node_t);
		n = tmp;
	}

	for i in range(0, queue.q.nprocs) {
		//cleanup(&queue->q, &queue->h[i]);
		n = queue.h(i).spare as u64;
		if (n != 0) {
			release_node(n as &mut node_t);
		}
	}

	runtime_release(0, queue as &mut [i8]);

	1
}


fn enq_fast(thread: thread_context, q: &mut queue_t, th: &mut handle_t, v: u64, id: &mut i32) -> bool
{
	let i = thread.atomic_add_global_i32(&mut (*q).Ei as &mut addrspace(1) i32, 1, memory_order::seq_cst);

	let c = find_cell(&mut (*th).Ep, i, th);
	let cv:u64 = BOT;

	let res = thread.atomic_cas_global_u64(&mut (*c).val as &mut addrspace(1) u64, cv, v, memory_order::seq_cst, memory_order::seq_cst);
	*id = i;

	res.1
}


fn enq_slow(thread: thread_context, q: &mut queue_t, th: &mut handle_t, v: u64, id: i32) -> ()
{
	let enq:&mut enq_t = &mut (*th).Er;
	let mut mid:i32 = id;
	
	thread.atomic_store_global_u64(&mut (*enq).val as &mut addrspace(1) u64, v, memory_order::seq_cst);
	thread.atomic_store_global_i32(&mut (*enq).id as &mut addrspace(1) i32, mid, memory_order::seq_cst);

	let mut tail:&mut node_t = thread.atomic_load_global_u64(&mut (*th).Ep as &mut addrspace(1) u64, memory_order::seq_cst) as &mut node_t;

	let mut i:i32;
	let mut c:&mut cell_t;

	// TODO: do-while
	while (thread.atomic_load_global_i32(&mut (*enq).id as &mut addrspace(1) i32, memory_order::seq_cst) > 0) {
		i = thread.atomic_add_global_i32(&mut (*q).Ei as &mut addrspace(1) i32, 1, memory_order::seq_cst);
		c = find_cell(&mut tail, i, th);
		let mut ce:u64 = BOT;

		let res_c = thread.atomic_cas_global_u64(&mut (*c).enq as &mut addrspace(1) u64, ce, enq as u64, memory_order::seq_cst, memory_order::seq_cst);
		let val_c = thread.atomic_load_global_u64(&mut (*c).val as &mut addrspace(1) u64, memory_order::seq_cst);
		if res_c.1 && val_c != TOP {
			let res_id = thread.atomic_cas_global_i32(&mut (*enq).id as &mut addrspace(1) i32, mid, -i, memory_order::seq_cst, memory_order::seq_cst);
			if res_id.1 {
				mid = -i;
				break()
			}
		}
	} 

	mid = -thread.atomic_load_global_i32(&mut (*enq).id as &mut addrspace(1) i32, memory_order::seq_cst);
	c = find_cell(&mut (*th).Ep, mid, th);

	if (mid > i) {
		let mut Ei:i32 = thread.atomic_load_global_i32(&mut (*q).Ei as &mut addrspace(1) i32, memory_order::seq_cst);
		while (Ei <= mid) {
			let res_Ei = thread.atomic_cas_global_i32(&mut (*q).Ei as &mut addrspace(1) i32, Ei, mid + 1, memory_order::seq_cst, memory_order::seq_cst);
			Ei = res_Ei.0;
			if res_Ei.1 { break() }
		}
	}

	thread.atomic_store_global_u64(&mut (*c).val as &mut addrspace(1) u64, v, memory_order::seq_cst);
}

fn enqueue_internal(thread: thread_context, q: &mut queue_t, th: &mut handle_t, v: u64) -> i32
{
	let Ep:u64 = thread.atomic_load_global_u64(&mut (*th).Ep as &mut addrspace(1) u64, memory_order::seq_cst);
	thread.atomic_store_global_u64(&mut (*th).Hp as &mut addrspace(1) u64, Ep, memory_order::seq_cst);

	let mut id:i32;
	let mut p = MAX_PATIENCE;
	while (!enq_fast(thread, q, th, v, &mut id) && p-- > 0) { };
	if (p < 0) { enq_slow(thread, q, th, v, id); }

	thread.atomic_store_global_u64(&mut (*th).Hp as &mut addrspace(1) u64, 0, memory_order::seq_cst);

	1
}






fn @createYangMellorCrummeyQueue(device: AccDevice, _queue_size: i32) -> ProducerConsumerQueue[u32] {
	// let queue_state_size = 80 as i64;

	//let num_handles = 100; //(1 << 21);
	// retrieve max_concurrency from device
	/*
	let dev_num_handles_buffer = device.alloc(sizeof[i32]());
	let dev_num_handles = dev_num_handles_buffer.data as &mut addrspace(1) i32;

	for grid in device.launch_1d(1, block_dim) {
		for thread in grid.threads() {
			if thread.idx(0) == 0 {
				*dev_num_handles = grid.max_concurrency();
			}
		}
	}

	let num_handles_buffer = alloc_cpu(sizeof[i32]());
	copy(dev_num_handles_buffer, num_handles_buffer);
	let num_handles = *(num_handles_buffer.data as &mut i32);
	release(num_handles_buffer);
	release(dev_num_handles_buffer);

	assert(0 < num_handles, "this device does not expose its max_concurrency");

	print_string("num_handles: "); print_i32(num_handles); print_char('\n');
	*/
	// let handle_buffer_size = num_handles * sizeof[YangMellorCrummey::Handle]();
	// let handle_buffer_alignment = alignof[YangMellorCrummey::Handle]();

	// let handle_data_offset = round_up_i64(queue_state_size, handle_buffer_alignment);

	// let queue_device_state_alloc = device.alloc(handle_data_offset + handle_buffer_size);
	// let queue_device_memory = queue_device_state_alloc.data as &mut addrspace(1) [u8];

	// let queue = &mut queue_device_memory(0) as &mut addrspace(1) [u8];
	// let handle = &mut queue_device_memory(handle_data_offset) as &mut addrspace(1) [u8];

	let mut queue:WFQHandle;

	//let success = wfqueue_create(default_num_handles, &mut queue);
	let success = wfqueue_create_internal(device, default_num_handles, &mut queue);
	assert(success > 0, "wfqueue_create() failed");

	let q = (*queue).q;
	device.print_i32("queue.q.Ei  %d\n", q.Ei);
	device.print_i32("queue.q.Di  %d\n", q.Di);
	device.print_i32("queue.q.Hi  %d\n", q.Hi);
	device.print_i32("queue.q.Hp  0x%x\n", q.Hp as i32);
	device.print_i32("queue.q.nprocs  %d\n", q.nprocs);
	print_string("queue.tail        "); print_i64((*queue).tail as i64); print_char('\n');
	print_string("queue.h(0)        "); print_i64((&mut (*queue).h(0)) as i64); print_char('\n');
	print_string("queue.h(-1).next  "); print_i64((*queue).h(q.nprocs - 1).next as i64); print_char('\n');

	ProducerConsumerQueue[u32] {
		push = @|source:fn()->u32| @|thread| {
			let id = thread.uid();
			//assert(handle < num_handles, "thread handle out of range");
			assert(0 <= id && id < (*queue).q.nprocs, "thread handle out of range");
			let value = source() as u64 | 0x00ff000000000000;
			//let success = wfqueue_try_enqueue_u32(queue, id, value);
			//void* value = (void*)(0x00ff000000000000UL | v);
			//let success = enqueue(&mut (*queue).q, &mut (*queue).h(id), value);
			let success = enqueue_internal(thread, &mut (*queue).q, &mut (*queue).h(id), value);
			//device.print_3xi32("push handle: %d - %d / %d\n", handle, value as i32, success);
			if success > 0 {
				thread.atomic_add_global_i32(&mut (*queue).size as &mut addrspace(1) i32, 1, memory_order::seq_cst);
				1
			} else { 0 }
		},

		pop = @|sink| @|thread| {
			let id = thread.uid();
			//assert(handle < num_handles, "thread handle out of range");
			assert(0 <= id && id < (*queue).q.nprocs, "thread handle out of range");
			let mut value:u32 = thread.idx(0);
			let success = wfqueue_try_dequeue_u32(queue, id, &mut value);
			//let v:u64 = dequeue(&mut (*queue).q, (*queue).h(id));

			//let success = (v != EMPTY);
			//value = (v & 0xffffffff) as u32;

			//device.print_3xi32("pop handle: %d - %d / %d\n", handle, value as i32, success);

			if success > 0 {
				//thread.atomic_sub_global_i32(&mut (*queue).size as &mut addrspace(1) i32, 1, memory_order::seq_cst);
				sink(value);
				1
			} else {
				0
			}
		},

		size = @|thread| {
			thread.atomic_load_global_i32(&mut (*queue).size as &addrspace(1) i32, memory_order::seq_cst)
			//wfqueue_size(queue)
		},

		reset = @|grid| {
			let num_handles = grid.max_concurrency();

			for thread in grid.threads() {
				if thread.idx(0) == 0 {
					let mut success:i32;
					//success = wfqueue_destroy(queue);
					success = wfqueue_destroy_internal(queue);
					assert(success > 0, "wfqueue_destroy() failed");
					//device.print_i32("num_handles: %d\n", num_handles);
					//success = wfqueue_create(num_handles, &mut queue);
					success = wfqueue_create_internal(device, num_handles, &mut queue);
					assert(success > 0, "wfqueue_create() failed");
				}
			}
			/*
			for thread in grid.threads() {
				for i in range_step(thread.idx(0) as i32, num_handles, grid.num_threads(0) as i32) {
					wfqueue_init(queue, i);
				}
			}
			*/
		},

		validate = @|_corrupted, _grid| {
		},

		release = @|| {
			wfqueue_destroy(queue);
		}
	}
}
