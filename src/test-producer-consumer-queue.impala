
fn main() -> i32 {
	let device = createAccDevice();

	let num_elements = (100 * 1024 * 1024) as u32;
	let queue_size = 1024 * 1024;
	let queue_test = createQueueTest(device, (num_elements + 1u32) * sizeof[u32]() as u32);
	let block_dim = 256;

	let ref_test = createBaseTest(device, (num_elements + 0u32) * sizeof[u32]() as u32);

	fn element(intrinsics: Intrinsics, i: u32) -> u32 {
		let rand_state = xorshift32(i);
		let octaves = (rand_state % 8u32) as i32;
		(simplexNoiseFractal([randf(i, intrinsics), randf(i * 2u32, intrinsics), randf(i * 3u32, intrinsics)], octaves, intrinsics) * 8.0f32) as u32
	}

	with device_memory, device_failed_flag in ref_test.run_test() {
		let ref_output = bitcast[&mut[1][u32]](device_memory);

		with queue, device_memory, device_failed_flag in queue_test.run_test(queue_size) {
			let output = bitcast[&mut[1][u32]](device_memory);
			let next_input = &mut output(num_elements);

			with grid, intrinsics in device.launch_1d(1, 1) {
				with thread in grid.threads() {
					*next_input = 0u32;
				}
			}

			with grid, intrinsics in device.launch_1d(42, block_dim) {
				with wave in grid.waves() {
					with thread in wave.threads() {
						// let mut rand_state = xorshift32(((wave.idx() + 23u32) * 42u32) as u32);

						fn producer(thread: gpu_thread_context, sink: fn(u32) -> ()) -> bool {
							let el = thread.atomic_add_global_u32(next_input, 1u32);

							if el < num_elements {
								sink(element(intrinsics, el));
								true
							}
							else {
								thread.atomic_exch_global_u32(next_input, num_elements);
								false
							}
						}

						fn consumer(thread: gpu_thread_context, el: u32) -> () {
							output(el) = el;
						}


						fn should_flush(thread: gpu_thread_context) -> bool {
							// let should_push = if rand_state as i32 < 0 { 1 } else { 0 };
							// if drain || wave.shfl_i32(should_push, 0, wave.num_threads()) == 0 {  // note: cannot use barrier_any(), would mess up the probabilities
							queue.size(thread) >= wave.num_threads() as i32
						}

						producer_consumer_loop_wave(wave, producer, consumer, queue, should_flush);
					}
				}
			}

			with grid, intrinsics in device.launch_1d(1, 1) {
				with thread in grid.threads() {
					if *next_input != num_elements {
						device.print_i32a("inconsistent next_input %d != %d\n", [*next_input as i32, num_elements as i32]);
						thread.atomic_exch_global_u32(device_failed_flag, -1u32);
					}
				}
			}

			queue_test.finish() == 0
		}

		with grid, intrinsics in device.launch_1d(div_up(num_elements as i32, block_dim), block_dim) {
			with thread in grid.threads() {
				for i in range_step(thread.idx(0) as i32, num_elements as i32, grid.num_threads(0) as i32) {
					let el = element(intrinsics, i as u32);
					ref_output(el) = el;
				}
			}
		}

		with grid, intrinsics in device.launch_1d(div_up(num_elements as i32, block_dim), block_dim) {
			with thread in grid.threads() {
				for i in range_step(thread.idx(0) as i32, num_elements as i32, grid.num_threads(0) as i32) {
				}
			}
		}

		true
	}

	ref_test.finish()
}
