
// inst_stats[x86_64]: extractelement(20), cmpxchg(4), insertelement(9), shufflevector(5), llvm.x86.avx.movmsk.ps.256(1), llvm.masked.store.v8i32.p1v8i32(1)

// vec_width(PE: total of 4 active lanes): 3x extractelement (cmp, new, lane active), 1x cmpxchg, 1x insertelement
// 4x insertelement + 4x shufflevector for broadcasts
// 8x extractelement, 1x insertelement + 1x shufflevector for masked fiber_yield


fn @setup_input(_num_globals: i32, _num_locals: i32) -> (fn(i32)->i32, fn(i32)->i32) {
	let global = @|_: i32| 0;
	let local  = @|l: i32| l;
	(global, local)
}

fn @test_body(grid: gpu_grid_context, read: ReadFn, write: WriteFn, global: GlobalFn) -> () {
	for thread in grid.threads() {
		let tidx = thread.idx(0) as i32;

		let mydata = read(tidx);
		let newdata = mydata + 2;

		if tidx & 0x1 == 0 {
			thread.wait(  // the fiber scheduler is not fair -> we need to yield if we wait for some other thread
				@|| thread.atomic_cas_global_i32_weak(global(0), mydata, newdata, memory_order::relaxed, memory_order::relaxed).1,
				"wait for some other thread to cas first");

			write(tidx, newdata);
		}
	}
}

fn @expected_result(_global: fn(i32)->i32, _local: fn(i32)->i32) -> (fn(i32)->i32, fn(i32)->i32) {
	let values = |l: i32| if l % 2 == 0 { l + 2 } else { l };
	let result = |g: i32| match g { 0 => 512, _ => 0x0 };

	(result, values)
}
